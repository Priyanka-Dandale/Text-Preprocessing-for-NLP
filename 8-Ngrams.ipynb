{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams  -continuous sequence of words\n",
    "\n",
    "**N-grams are continuous sequences of ùëõ items** (words, characters, or tokens) extracted from a given text. In Natural Language Processing (NLP), they are commonly used to represent or analyze textual data.  \n",
    "\n",
    "**Key Concepts:**  \n",
    "- Unigrams: Single words/tokens.  \n",
    "Example: \"I love NLP\" ‚Üí [\"I\", \"love\", \"NLP\"]    \n",
    "\n",
    "- Bigrams: Two consecutive words.   \n",
    "Example: \"I love NLP\" ‚Üí [(\"I\", \"love\"), (\"love\", \"NLP\")]    \n",
    "\n",
    "- Trigrams: Three consecutive words.  \n",
    "Example: \"I love NLP\" ‚Üí [(\"I\", \"love\", \"NLP\")]    \n",
    "\n",
    "- N-grams: General form for sequences of ùëõ consecutive items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['but' 'fantastic' 'great' 'hated' 'it' 'loved' 'movie' 'not' 'okay'\n",
      " 'terrible' 'the' 'was']\n",
      "Document-Term Matrix:\n",
      " [[0 1 0 0 1 1 1 0 0 0 1 1]\n",
      " [1 0 1 0 0 0 1 1 1 0 1 1]\n",
      " [0 0 0 1 1 0 1 0 0 1 1 1]]\n",
      "(3, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Sample corpus of movie reviews\n",
    "corpus = [\n",
    "    \"I loved the movie, it was fantastic!\",\n",
    "    \"The movie was okay, but not great.\",\n",
    "    \"I hated the movie, it was terrible.\",\n",
    "]\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the corpus to a document-term matrix\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert the document-term matrix into a dense format (optional for visualization)\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Get the vocabulary (mapping of words to index positions)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the vocabulary and document-term matrix\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Document-Term Matrix:\\n\", X_dense)\n",
    "print(X_dense.shape)   # 3 obs and 12 vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loved': 5,\n",
       " 'the': 10,\n",
       " 'movie': 6,\n",
       " 'it': 4,\n",
       " 'was': 11,\n",
       " 'fantastic': 1,\n",
       " 'okay': 8,\n",
       " 'but': 0,\n",
       " 'not': 7,\n",
       " 'great': 2,\n",
       " 'hated': 3,\n",
       " 'terrible': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['but' 'fantastic' 'great' 'hated' 'it' 'loved' 'movie' 'not' 'okay'\n",
      " 'terrible' 'the' 'was']\n",
      "Document-Term Matrix:\n",
      " [[0 1 0 0 1 1 1 0 0 0 1 1]\n",
      " [1 0 1 0 0 0 1 1 1 0 1 1]\n",
      " [0 0 0 1 1 0 1 0 0 1 1 1]]\n",
      "(3, 12)\n"
     ]
    }
   ],
   "source": [
    "##Unigrams ngram_range=(1,1)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Sample corpus of movie reviews\n",
    "corpus = [\n",
    "    \"I loved the movie, it was fantastic!\",\n",
    "    \"The movie was okay, but not great.\",\n",
    "    \"I hated the movie, it was terrible.\",\n",
    "]\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "\n",
    "# Fit and transform the corpus to a document-term matrix\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert the document-term matrix into a dense format (optional for visualization)\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Get the vocabulary (mapping of words to index positions)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the vocabulary and document-term matrix\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Document-Term Matrix:\\n\", X_dense)\n",
    "print(X_dense.shape)   # 3 obs and 12 vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['but' 'but not' 'fantastic' 'great' 'hated' 'hated the' 'it' 'it was'\n",
      " 'loved' 'loved the' 'movie' 'movie it' 'movie was' 'not' 'not great'\n",
      " 'okay' 'okay but' 'terrible' 'the' 'the movie' 'was' 'was fantastic'\n",
      " 'was okay' 'was terrible']\n",
      "Document-Term Matrix:\n",
      " [[0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0]\n",
      " [1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0]\n",
      " [0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 1]]\n",
      "(3, 24)\n"
     ]
    }
   ],
   "source": [
    "##Unigrams and Bigrams ngram_range=(1,2)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Sample corpus of movie reviews\n",
    "corpus = [\n",
    "    \"I loved the movie, it was fantastic!\",\n",
    "    \"The movie was okay, but not great.\",\n",
    "    \"I hated the movie, it was terrible.\",\n",
    "]\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# Fit and transform the corpus to a document-term matrix\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert the document-term matrix into a dense format (optional for visualization)\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Get the vocabulary (mapping of words to index positions)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the vocabulary and document-term matrix\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Document-Term Matrix:\\n\", X_dense)\n",
    "print(X_dense.shape)   # 3 obs and 12 vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['but not' 'hated the' 'it was' 'loved the' 'movie it' 'movie was'\n",
      " 'not great' 'okay but' 'the movie' 'was fantastic' 'was okay'\n",
      " 'was terrible']\n",
      "Document-Term Matrix:\n",
      " [[0 0 1 1 1 0 0 0 1 1 0 0]\n",
      " [1 0 0 0 0 1 1 1 1 0 1 0]\n",
      " [0 1 1 0 1 0 0 0 1 0 0 1]]\n",
      "(3, 12)\n"
     ]
    }
   ],
   "source": [
    "##Bigrams ngram_range=(2,2)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Sample corpus of movie reviews\n",
    "corpus = [\n",
    "    \"I loved the movie, it was fantastic!\",\n",
    "    \"The movie was okay, but not great.\",\n",
    "    \"I hated the movie, it was terrible.\",\n",
    "]\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Fit and transform the corpus to a document-term matrix\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert the document-term matrix into a dense format (optional for visualization)\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Get the vocabulary (mapping of words to index positions)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the vocabulary and document-term matrix\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Document-Term Matrix:\\n\", X_dense)\n",
    "print(X_dense.shape)   # 3 obs and 12 vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['but not great' 'hated the movie' 'it was fantastic' 'it was terrible'\n",
      " 'loved the movie' 'movie it was' 'movie was okay' 'okay but not'\n",
      " 'the movie it' 'the movie was' 'was okay but']\n",
      "Document-Term Matrix:\n",
      " [[0 0 1 0 1 1 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 1 1 0 1 1]\n",
      " [0 1 0 1 0 1 0 0 1 0 0]]\n",
      "(3, 11)\n"
     ]
    }
   ],
   "source": [
    "##Trigrams ngram_range=(3,3)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Sample corpus of movie reviews\n",
    "corpus = [\n",
    "    \"I loved the movie, it was fantastic!\",\n",
    "    \"The movie was okay, but not great.\",\n",
    "    \"I hated the movie, it was terrible.\",\n",
    "]\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(3,3))\n",
    "\n",
    "# Fit and transform the corpus to a document-term matrix\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert the document-term matrix into a dense format (optional for visualization)\n",
    "X_dense = X.toarray()\n",
    "\n",
    "# Get the vocabulary (mapping of words to index positions)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the vocabulary and document-term matrix\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Document-Term Matrix:\\n\", X_dense)\n",
    "print(X_dense.shape)   # 3 obs and 12 vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams: [('I', 'love'), ('love', 'learning'), ('learning', 'NLP'), ('NLP', 'and'), ('and', 'Python')]\n",
      "Trigrams: [('I', 'love', 'learning'), ('love', 'learning', 'NLP'), ('learning', 'NLP', 'and'), ('NLP', 'and', 'Python')]\n"
     ]
    }
   ],
   "source": [
    "##using nltk\n",
    " \n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Input text\n",
    "text = \"I love learning NLP and Python\".split()\n",
    "\n",
    "# Generate n-grams (e.g., bigrams)\n",
    "bigrams = list(ngrams(text, 2))\n",
    "trigrams = list(ngrams(text, 3))\n",
    "\n",
    "print(\"Bigrams:\", bigrams)\n",
    "print(\"Trigrams:\", trigrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
